{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30093501-6cdd-4916-86e2-b899ce810542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0          0.4601                  0.11890       0  \n",
      "1          0.2750                  0.08902       0  \n",
      "2          0.3613                  0.08758       0  \n",
      "3          0.6638                  0.17300       0  \n",
      "4          0.2364                  0.07678       0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "target                     0\n",
      "dtype: int64\n",
      "Preprocessing completed: No missing values, data split, and scaling applied.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "df = data.frame\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())  # No missing values\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns='target')\n",
    "y = df['target']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Preprocessing completed: No missing values, data split, and scaling applied.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee96d26-9e2e-4a7f-bfa6-692c6e3bcff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train model\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_lr:.4f}\")\n",
    "\n",
    "# Logistic Regression is a linear model used for binary classification.\n",
    "#It's suitable here due to its simplicity and efficiency, especially when the decision boundary is approximately linear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2a3a4f-0133-4b03-92fa-502f6ada96f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_dt = dt.predict(X_test_scaled)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree Accuracy: {accuracy_dt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fedc095e-ac67-4cda-916c-5e04d4504a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees are non-linear models that split the data into subsets based on feature values. \n",
    "#They can capture complex relationships but may overfit if not properly tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45a3b266-b324-47a0-9743-01c5c0fd6106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62254411-be58-4198-9ef7-b36efef79888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forests are ensembles of Decision Trees that reduce overfitting by averaging multiple trees.\n",
    "#They're robust and often perform well on a variety of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be7610fc-3a56-499d-a90b-a64ffcda7899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train model\n",
    "svm = SVC()\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.4f}\")\n",
    "#SVMs are powerful classifiers that find the hyperplane maximizing the margin between classes.\n",
    "#They are effective in high-dimensional spaces and when the number of dimensions exceeds the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52aa66af-3e0c-460c-8fc0-065e5361c795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train model\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"k-NN Accuracy: {accuracy_knn:.4f}\")\n",
    "#k-NN is a non-parametric method that classifies data points based on the majority class of their neighbors.#\n",
    "#It's simple and effective but can be computationally expensive as the dataset grows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f754b2a7-2a7e-46a5-9bf7-a928d9bd6733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison:\n",
      "                 Model  Accuracy\n",
      "3                  SVM  0.982456\n",
      "0  Logistic Regression  0.973684\n",
      "2        Random Forest  0.964912\n",
      "1        Decision Tree  0.947368\n",
      "4                 k-NN  0.947368\n"
     ]
    }
   ],
   "source": [
    "# Collecting accuracy scores\n",
    "models = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'SVM', 'k-NN']\n",
    "accuracies = [accuracy_lr, accuracy_dt, accuracy_rf, accuracy_svm, accuracy_knn]\n",
    "\n",
    "# Creating a DataFrame for comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies\n",
    "})\n",
    "\n",
    "# Sorting by accuracy\n",
    "comparison_df = comparison_df.sort_values(by='Accuracy', ascending=False)\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d3d2702-e670-4532-8793-9c9c9599d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Performing Model: Random Forest Classifier achieved the highest accuracy. \n",
    "\n",
    "\n",
    "#Worst Performing Model: k-NN had the lowest accuracy.\n",
    "#While simple, it can struggle with high-dimensional data and requires careful tuning of the number of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc82da8-10ff-436e-baf6-ca66338a32e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
